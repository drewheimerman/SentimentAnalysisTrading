{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,nltk,re,math,time\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import _pickle as pc\n",
    "\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import tweepy, nltk, csv, pickle, collections\n",
    "import numpy as np\n",
    "from nltk.sentiment import sentiment_analyzer\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions for formating data and extracting features\n",
    "\n",
    "def formatInputData(input_data): # Format input data to ([text_tokens], SA_classifer) tuples\n",
    "    formattedSentimentData = []\n",
    "    for i in range(0, len(input_data)):\n",
    "        ## Change df type\n",
    "        formattedSentimentData.append((input_data['tweets'][i].text.split(), input_data['Classification'][i]))\n",
    "    return (formattedSentimentData)\n",
    "def feature_extract_func(document, word_features): # Apply feature definement to tweet text\n",
    "    #doc_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in doc_words)\n",
    "    return features\n",
    "def get_word_features(wordlist): # Get words of all tweets, arranged by frequency\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features\n",
    "def train_SA_classifier(input_data):\n",
    "    # Define Sent_analysis and cross-validation wrapper\n",
    "    SA = sentiment_analyzer.SentimentAnalyzer()\n",
    "    # Prepare features\n",
    "    all_words = get_word_features(SA.all_words(input_data))\n",
    "    word_features = get_word_features(all_words)\n",
    "    SA.add_feat_extractor(feature_extract_func, **{'word_features': word_features})\n",
    "    training_set = SA.apply_features(input_data, labeled=True)  \n",
    "    # Return classifier and write to file\n",
    "    return (SA.train(NaiveBayesClassifier.train, training_set, save_classifier='sentiment_analysis_classifier'), word_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amzn = pd.read_pickle('amzn_sample_data.p')\n",
    "goog = pd.read_pickle('google_sample_data.pkl')\n",
    "msft = pd.read_pickle('msft_sample_data.p')\n",
    "aapl = pd.read_pickle('aapl_sample_data.p')\n",
    "input_data = pd.concat([aapl, amzn, goog, msft])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = pd.read_pickle('preprocessed_training.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>followers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-11-21 19:02:27</th>\n",
       "      <td>[', 1, ']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 21:10:54</th>\n",
       "      <td>[', 0, ']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 20:17:55</th>\n",
       "      <td>[', 0, ']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 21:33:05</th>\n",
       "      <td>[', -, ', ', 1, ']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 18:37:06</th>\n",
       "      <td>[', 0, ']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text  retweets  favorites  followers\n",
       "date                                                                   \n",
       "2016-11-21 19:02:27           [', 1, ']       0.0        0.0        0.0\n",
       "2016-11-21 21:10:54           [', 0, ']       0.0        0.0        0.0\n",
       "2016-11-21 20:17:55           [', 0, ']       0.0        0.0        0.0\n",
       "2016-11-21 21:33:05  [', -, ', ', 1, ']       0.0        0.0        0.0\n",
       "2016-11-21 18:37:06           [', 0, ']       0.0        0.0        0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------DATA--------------------------------\n",
      "\n",
      "COUNTS(2000) -- Positive: 474, Neutral: 1204, Negative: 322\n",
      "\n",
      "  0    1204\n",
      " 1     474\n",
      "-1     322\n",
      "Name: Classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "input_data_counts = input_data['Classification'].value_counts()\n",
    "print ('-------------------------------DATA--------------------------------\\n')\n",
    "print ('COUNTS(%d) -- Positive: %d, Neutral: %d, Negative: %d' %(input_data['Classification'].count(), input_data_counts[1], input_data_counts[0], input_data_counts[-1]))\n",
    "print ('\\n', input_data_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SentimentAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------RUN MODEL--------------------------------\n",
      "\n",
      "Training classifier\n",
      "Saving sentiment_analysis_classifier\n"
     ]
    }
   ],
   "source": [
    "print ('\\n-------------------------------RUN MODEL--------------------------------\\n')\n",
    "SA_classifier, word_features = train_SA_classifier(formatInputData(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_classifier.classify(feature_extract_func(input_data.iloc[0]['tweets'].text.split(), word_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert old Data format to new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Volume</th>\n",
       "      <th>favorites</th>\n",
       "      <th>followers</th>\n",
       "      <th>length</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-11-21 19:02:27</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Status(in_reply_to_user_id=None, id_str='80077...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 21:10:54</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Status(in_reply_to_user_id=None, extended_enti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 20:17:55</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Status(in_reply_to_user_id=None, id_str='80079...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 21:33:05</th>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Status(in_reply_to_user_id=None, id_str='80081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 18:37:06</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Status(in_reply_to_user_id=None, id_str='80077...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classification  Volume  favorites  followers  length  \\\n",
       "2016-11-21 19:02:27               1     NaN        NaN        NaN     NaN   \n",
       "2016-11-21 21:10:54               0     NaN        NaN        NaN     NaN   \n",
       "2016-11-21 20:17:55               0     NaN        NaN        NaN     NaN   \n",
       "2016-11-21 21:33:05              -1     NaN        NaN        NaN     NaN   \n",
       "2016-11-21 18:37:06               0     NaN        NaN        NaN     NaN   \n",
       "\n",
       "                     retweets text  \\\n",
       "2016-11-21 19:02:27       NaN  NaN   \n",
       "2016-11-21 21:10:54       NaN  NaN   \n",
       "2016-11-21 20:17:55       NaN  NaN   \n",
       "2016-11-21 21:33:05       NaN  NaN   \n",
       "2016-11-21 18:37:06       NaN  NaN   \n",
       "\n",
       "                                                                tweets  \n",
       "2016-11-21 19:02:27  Status(in_reply_to_user_id=None, id_str='80077...  \n",
       "2016-11-21 21:10:54  Status(in_reply_to_user_id=None, extended_enti...  \n",
       "2016-11-21 20:17:55  Status(in_reply_to_user_id=None, id_str='80079...  \n",
       "2016-11-21 21:33:05  Status(in_reply_to_user_id=None, id_str='80081...  \n",
       "2016-11-21 18:37:06  Status(in_reply_to_user_id=None, id_str='80077...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data['text'] = [tweet.text for tweet in input_data['tweets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Volume</th>\n",
       "      <th>favorites</th>\n",
       "      <th>followers</th>\n",
       "      <th>length</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-11-21 19:02:27</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benzinga: Previewing #BlackFriday Week: Apple ...</td>\n",
       "      <td>Status(in_reply_to_user_id=None, id_str='80077...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 21:10:54</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$AAPL Put Spread Trades 1,300 Times</td>\n",
       "      <td>Status(in_reply_to_user_id=None, extended_enti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 20:17:55</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Apple offers iPhone 6S owners free battery re...</td>\n",
       "      <td>Status(in_reply_to_user_id=None, id_str='80079...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 21:33:05</th>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$AAPL:\\n\\nForget Apple! Here’s a Better Stock ...</td>\n",
       "      <td>Status(in_reply_to_user_id=None, id_str='80081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 18:37:06</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apple $AAPL Should Buy Netflix to Boost Growth...</td>\n",
       "      <td>Status(in_reply_to_user_id=None, id_str='80077...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classification  Volume  favorites  followers  length  \\\n",
       "2016-11-21 19:02:27               1     NaN        NaN        NaN     NaN   \n",
       "2016-11-21 21:10:54               0     NaN        NaN        NaN     NaN   \n",
       "2016-11-21 20:17:55               0     NaN        NaN        NaN     NaN   \n",
       "2016-11-21 21:33:05              -1     NaN        NaN        NaN     NaN   \n",
       "2016-11-21 18:37:06               0     NaN        NaN        NaN     NaN   \n",
       "\n",
       "                     retweets  \\\n",
       "2016-11-21 19:02:27       NaN   \n",
       "2016-11-21 21:10:54       NaN   \n",
       "2016-11-21 20:17:55       NaN   \n",
       "2016-11-21 21:33:05       NaN   \n",
       "2016-11-21 18:37:06       NaN   \n",
       "\n",
       "                                                                  text  \\\n",
       "2016-11-21 19:02:27  Benzinga: Previewing #BlackFriday Week: Apple ...   \n",
       "2016-11-21 21:10:54              $AAPL Put Spread Trades 1,300 Times     \n",
       "2016-11-21 20:17:55  #Apple offers iPhone 6S owners free battery re...   \n",
       "2016-11-21 21:33:05  $AAPL:\\n\\nForget Apple! Here’s a Better Stock ...   \n",
       "2016-11-21 18:37:06  Apple $AAPL Should Buy Netflix to Boost Growth...   \n",
       "\n",
       "                                                                tweets  \n",
       "2016-11-21 19:02:27  Status(in_reply_to_user_id=None, id_str='80077...  \n",
       "2016-11-21 21:10:54  Status(in_reply_to_user_id=None, extended_enti...  \n",
       "2016-11-21 20:17:55  Status(in_reply_to_user_id=None, id_str='80079...  \n",
       "2016-11-21 21:33:05  Status(in_reply_to_user_id=None, id_str='80081...  \n",
       "2016-11-21 18:37:06  Status(in_reply_to_user_id=None, id_str='80077...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier = classify_tweet_sentiment(SA_classifier, word_features)\n",
    "classifiers = classifier.classify_tweets(input_data[:100])\n",
    "collections.Counter(classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification</th>\n",
       "      <th>Volume</th>\n",
       "      <th>favorites</th>\n",
       "      <th>followers</th>\n",
       "      <th>length</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-11-21 19:02:27</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Status(in_reply_to_user_id=None, id_str='80077...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 21:10:54</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Status(in_reply_to_user_id=None, extended_enti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 20:17:55</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Status(in_reply_to_user_id=None, id_str='80079...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 21:33:05</th>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Status(in_reply_to_user_id=None, id_str='80081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21 18:37:06</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Status(in_reply_to_user_id=None, id_str='80077...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classification  Volume  favorites  followers  length  \\\n",
       "2016-11-21 19:02:27               1     NaN        NaN        NaN     NaN   \n",
       "2016-11-21 21:10:54               0     NaN        NaN        NaN     NaN   \n",
       "2016-11-21 20:17:55               0     NaN        NaN        NaN     NaN   \n",
       "2016-11-21 21:33:05              -1     NaN        NaN        NaN     NaN   \n",
       "2016-11-21 18:37:06               0     NaN        NaN        NaN     NaN   \n",
       "\n",
       "                     retweets text  \\\n",
       "2016-11-21 19:02:27       NaN  NaN   \n",
       "2016-11-21 21:10:54       NaN  NaN   \n",
       "2016-11-21 20:17:55       NaN  NaN   \n",
       "2016-11-21 21:33:05       NaN  NaN   \n",
       "2016-11-21 18:37:06       NaN  NaN   \n",
       "\n",
       "                                                                tweets  \n",
       "2016-11-21 19:02:27  Status(in_reply_to_user_id=None, id_str='80077...  \n",
       "2016-11-21 21:10:54  Status(in_reply_to_user_id=None, extended_enti...  \n",
       "2016-11-21 20:17:55  Status(in_reply_to_user_id=None, id_str='80079...  \n",
       "2016-11-21 21:33:05  Status(in_reply_to_user_id=None, id_str='80081...  \n",
       "2016-11-21 18:37:06  Status(in_reply_to_user_id=None, id_str='80077...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "STOCKS = ['aapl','goog','amzn','msft']\n",
    "SYMBOLS = ['@','#','$','.',',',':', '…','...','(',')','\"','[',']']\n",
    "REMOVABLES = ['rt'] #'the', 'my','i','we','me','you']\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "EMOTICONS = [(':)','smile'), ('(:','smile'), ('):','frown'), (':(','frown'), (':D','biggrin'), (':\\'(','crying'), (':\\'‑(','crying'), (')\\':','crying'), (')-\\':','crying'), ('D:','sadness'), (':O','surprise'), (':o','shock') ]\n",
    "\n",
    "def preprocess(pdata, file = False):\n",
    "    print('Preprocessing...')\n",
    "    \n",
    "    if file:\n",
    "        dataframe = pd.read_pickle(pdata) #get pickled dataset from location passed in as a parameter to the function\n",
    "    if not file:\n",
    "        dataframe = pdata\n",
    "    preprocessed_dataframe = pd.DataFrame(columns=['Classification','volume','favorites','followers','length', 'retweets', 'text', 'tweets']).set_index('date')\n",
    "    \n",
    "    ##ITERATE THROUGH EVERY TWEET IN THE DATAFRAME\n",
    "    for it, tweet in tqdm.tqdm(dataframe.iterrows()):\n",
    "        text = str(tweet['text'])\n",
    "        retweets = tweet['retweets']\n",
    "        favorites = tweet['favorites']\n",
    "        followers = tweet['followers']\n",
    "        date = it\n",
    "        \n",
    "        ##if either retweets, favorites, or followers is NaN, replace NaN with 0\n",
    "        if(math.isnan(retweets)):\n",
    "            retweets = 0\n",
    "        if(math.isnan(favorites)):\n",
    "            favorites = 0\n",
    "        if(math.isnan(followers)):\n",
    "            followers = 0\n",
    "            \n",
    "        #text = text+':) :( :) :(' #TEST for emoticon replacement\n",
    "        #text = text+\"gooooood, jeeeeezz\" #TEST for repeated letter reduction\n",
    "        \n",
    "        text = text.replace('#','') #remove hashes\n",
    "        text = text.replace('%', 'percent')\n",
    "        ##Iterate though listed emoticons and their corrisponding emotions, replace symbol with emotion word\n",
    "        for symbol, emotion  in EMOTICONS:\n",
    "            text = text.replace(symbol, emotion)\n",
    "            \n",
    "        text =  re.sub(r\"http\\S+\", \"\", text) #remove URLs from Tweet text\n",
    "        #text = re.sub(r'([a-zA-Z])\\1{3,}', r'\\1\\1\\1', text) #reduce excessively long repeated letters ##REPLACED BY TweetTokenizer built-in function\n",
    "        tk = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True) #create new TweetTokenizer, take all text to lowercase and remove users handles from Tweet text\n",
    "        tk2 = MWETokenizer()\n",
    "        \n",
    "        tokenizedtext = tk.tokenize(text) #tokenize the Tweet text using TweetTokenizer\n",
    "        tokenizedtext = tk2.tokenize(tokenizedtext)\n",
    "        tokenizedtext = [word for word in tokenizedtext if (word not in STOPWORDS and word not in SYMBOLS and word not in STOCKS and word not in REMOVABLES)] #remove stopwords, extra symbols, target stocks, and other removable phrases\n",
    "        \n",
    "        temp = pd.DataFrame({\n",
    "            'date':date,\n",
    "            'text':[tokenizedtext],\n",
    "            'retweets':retweets,\n",
    "            'favorites':favorites,\n",
    "            'followers':followers\n",
    "        }, columns=['Classification','volume','favorites','followers','length', 'retweets', 'text', 'tweets']).set_index('date')\n",
    "        preprocessed_dataframe = preprocessed_dataframe.append(temp)\n",
    "        \n",
    "    #print(preprocessed_dataframe) #printout of the preprocessed dataframe\n",
    "    preprocessed_dataframe.to_pickle('preprocessed_tweets_s'+str(int(len(dataframe)/100))+'.p') #create a pickled dataframe with a semi-unique identifier (based on the number of rows in the dataframe)\n",
    "    return preprocessed_dataframe #return the dataframe\n",
    "    \n",
    "#preprocess('final_data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4443)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4289)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13733)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13687)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-4910290fbe58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'preprocessed_training.p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-135e4abb0fdd>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(pdata, file)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpreprocessed_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Classification'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'volume'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'favorites'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'followers'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'retweets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tweets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m##ITERATE THROUGH EVERY TWEET IN THE DATAFRAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   2915\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2917\u001b[0;31m                 \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2918\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2919\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3540\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3541\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3542\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3543\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4443)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4289)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13733)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13687)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "pd.to_pickle(preprocess(input_data), 'preprocessed_training.p') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
